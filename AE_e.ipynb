{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -sf\n",
    "\n",
    "from time import time\n",
    "time_start = time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import get_data as gd\n",
    "import atlas_plot as ap\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # set random seed\n",
    "sampling = int(1e5)\n",
    "processor = gd.DataProcessor(sampling=sampling, processor=10)\n",
    "path = \"/root/work/truth/signal/*npz\"\n",
    "processor.load_files(path)\n",
    "data = gd.Data(*processor.files)\n",
    "# print(dir(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEV = 1e3\n",
    "\n",
    "cut_pre_pt_lead = data.LeadLep[\"pt\"] > 22 * GEV\n",
    "cut_pre_pt_sub = data.SubLep[\"pt\"] > 15 * GEV\n",
    "cut_pre_dilep_m = data.diLep[\"m\"] > 10 * GEV\n",
    "cut_pre_pt_miss = data.MET[\"pt\"] > 20 * GEV\n",
    "cut_pre = cut_pre_pt_lead & cut_pre_pt_sub & cut_pre_dilep_m & cut_pre_pt_miss\n",
    "\n",
    "del (cut_pre_pt_lead, cut_pre_pt_sub, cut_pre_dilep_m, cut_pre_pt_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y -> observed params\n",
    "lep_p = processor.process_part(data.LepP)[cut_pre]\n",
    "lep_m = processor.process_part(data.LepM)[cut_pre]\n",
    "lep_kin = pd.concat([lep_p, lep_m], axis=1)\n",
    "MET = processor.process_MET(data.MET).iloc[:, 1:3][cut_pre]\n",
    "MET_kin = pd.concat([MET, lep_kin], axis=1)\n",
    "print(\"MET_kin shape:\", MET_kin.shape)\n",
    "print(MET_kin.head(3))\n",
    "print()\n",
    "\n",
    "# x -> interested unknowns\n",
    "dinu_kin = pd.DataFrame(processor.process_dipart(data.LepP, data.LepM)[\"E\"][cut_pre])\n",
    "print(\"dinu_kin shape:\", dinu_kin.shape)\n",
    "print(dinu_kin.head(3))\n",
    "print()\n",
    "\n",
    "del (processor, lep_p, lep_m, MET)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SCALAR_int = StandardScaler()\n",
    "norm_var = SCALAR_int.fit_transform(dinu_kin)\n",
    "dinu_kin = norm_var\n",
    "\n",
    "SCALAR_MET = StandardScaler()\n",
    "norm_var = SCALAR_MET.fit_transform(MET_kin)\n",
    "MET_kin = norm_var\n",
    "\n",
    "del norm_var\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices_arr = np.arange(dinu_kin.shape[0], dtype=\"int\")\n",
    "indices_arr = np.random.choice(indices_arr, sampling)\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    indices_arr.flatten(), train_size=0.8, test_size=0.2, random_state=42\n",
    ")\n",
    "valid_indices, test_indices = train_test_split(\n",
    "    temp_indices, train_size=0.5, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "train_x = dinu_kin[train_indices]\n",
    "valid_x = dinu_kin[valid_indices]\n",
    "test_x = dinu_kin[test_indices]\n",
    "train_y = MET_kin[train_indices]\n",
    "valid_y = MET_kin[valid_indices]\n",
    "test_y = MET_kin[test_indices]\n",
    "\n",
    "print(\n",
    "    f\"X (Interest)\\nTraining data shape: {train_x.shape};\\nValiding data shape: {valid_x.shape};\\nTesting data shape: {test_x.shape}.\"\n",
    ")\n",
    "print(\n",
    "    f\"Y (Observed)\\nTraining data shape: {train_y.shape};\\nValiding data shape: {valid_y.shape};\\nTesting data shape: {test_y.shape}.\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # encoder\n",
    "    model.add(layers.Flatten(input_shape=(train_y.shape[-1],)))\n",
    "    # model.add(layers.Dense(units=8, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units=4, activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    # bottleneck\n",
    "    model.add(layers.Dense(units=2, activation=\"relu\"))\n",
    "    # decoder\n",
    "    model.add(layers.Dense(units=4, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units=8, activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    # Last dense layers\n",
    "    model.add(layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "import datetime\n",
    "\n",
    "# set log file\n",
    "%rm -r ./logs\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# set callback of tensorboard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=5, write_graph=True, write_images=False,)\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-6,\n",
    "    patience=10,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x=train_y,\n",
    "    y=train_x,\n",
    "    validation_data=(valid_y, valid_x),\n",
    "    epochs=512,\n",
    "    batch_size=256,\n",
    "    verbose=2,\n",
    "    callbacks=[stop_early, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('AE_e.h5')\n",
    "# predict\n",
    "x_pred = model.predict(test_y)\n",
    "sig_pred = x_pred.flatten()\n",
    "sig_truth = test_x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "plot = ap.Plotter()\n",
    "range = [-0.5, 4]\n",
    "\n",
    "plot.plot_hist(\n",
    "    [sig_truth, sig_pred],\n",
    "    [r\"$E_{truth}^{\\nu\\nu}$\", r\"$E_{pred}^{\\nu\\nu}$\"],\n",
    "    r\"Signal: Normalized $E$ of $\\nu\\nu$\",\n",
    "    range=range,\n",
    "    xlabel=r\"$E$ [GeV]\",\n",
    ")\n",
    "\n",
    "plot.plot_loss_history(history, logy=True)\n",
    "\n",
    "plot.plot_2d_histogram(\n",
    "    sig_pred,\n",
    "    sig_truth,\n",
    "    \"Signal: \"\n",
    "    + r\"$E^{\\nu\\nu}$ \"\n",
    "    + f\"with Pearson coeff: {sp.stats.pearsonr(sig_truth, sig_pred)[0]:.3f}\",\n",
    "    range=range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "processor = gd.DataProcessor(sampling=sampling, processor=10)\n",
    "path = \"/root/work/truth/background/*npz\"\n",
    "processor.load_files(path)\n",
    "data = gd.Data(*processor.files)\n",
    "# print(dir(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y -> observed params\n",
    "lep_p = processor.process_part(data.LepP)[cut_pre]\n",
    "lep_m = processor.process_part(data.LepM)[cut_pre]\n",
    "lep_kin = pd.concat([lep_p, lep_m], axis=1)\n",
    "MET = processor.process_MET(data.MET).iloc[:, 1:3][cut_pre]\n",
    "MET_kin = pd.concat([MET, lep_kin], axis=1)\n",
    "print(\"MET_kin shape:\", MET_kin.shape)\n",
    "print(MET_kin.head(3))\n",
    "print()\n",
    "\n",
    "# x -> interested unknowns\n",
    "dinu_kin = pd.DataFrame(processor.process_dipart(data.LepP, data.LepM)[\"E\"][cut_pre])\n",
    "print(\"dinu_kin shape:\", dinu_kin.shape)\n",
    "print(dinu_kin.head(3))\n",
    "print()\n",
    "\n",
    "del (processor, lep_p, lep_m, MET)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALAR_int_bkg = StandardScaler()\n",
    "norm_var = SCALAR_int.fit_transform(dinu_kin)\n",
    "dinu_kin = norm_var\n",
    "\n",
    "SCALAR_MET_bkg = StandardScaler()\n",
    "norm_var = SCALAR_MET.fit_transform(MET_kin)\n",
    "MET_kin = norm_var\n",
    "\n",
    "del norm_var\n",
    "\n",
    "x, y = dinu_kin[indices_arr], MET_kin[indices_arr]\n",
    "\n",
    "print(f\"X (Interest) data shape: {x.shape};\\nY (Observed) data shape: {y.shape}.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(y)\n",
    "bkg_pred = x_pred.flatten()\n",
    "bkg_truth = x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = ap.Plotter()\n",
    "\n",
    "range = [-0.5, 4]\n",
    "\n",
    "plot.plot_hist(\n",
    "    [bkg_truth, bkg_pred],\n",
    "    [r\"$E_{truth}^{\\nu\\nu}$\", r\"$E_{pred}^{\\nu\\nu}$\"],\n",
    "    \"Non-resnt WW: \" + r\"Normalized $E$ of $\\nu\\nu$\",\n",
    "    range=range,\n",
    "    xlabel=r\"$E$ [GeV]\",\n",
    ")\n",
    "\n",
    "plot.plot_2d_histogram(\n",
    "    bkg_pred,\n",
    "    bkg_truth,\n",
    "    \"Non-resnt WW: \"\n",
    "    + r\"$E^{\\nu\\nu}$ \"\n",
    "    + f\"with Pearson coeff: {sp.stats.pearsonr(bkg_truth, bkg_pred)[0]:.3f}\",\n",
    "    range=range,\n",
    ")\n",
    "\n",
    "time_end = time()\n",
    "print(f\"Time cost: {(time_end - time_start):.2f} s.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
